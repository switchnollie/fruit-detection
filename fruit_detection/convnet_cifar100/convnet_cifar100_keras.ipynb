{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.datasets import cifar100\n",
    "from keras.utils import to_categorical\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für unser Modell nutzen wir den CIFAR100-Datensatz, der über das Modul *keras.datasets* zur Verfügung steht. Dieser besteht aus insgesamt **60000 farbigen Bildern** aufgeteilt in **50000 Trainingsbilder** und **10000 Testbildern**. Die Bilder haben jeweils eine Auflösung von **32x32 Pixeln** und können folgendermaßen geladen werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainings- und Testdaten können über *cifar100.load_data()* geladen werden. Der Datensatz setzt sich aus Kategorien samt Subkategorien zusammen. Über das Argument *label_mode* fordern wir alle Subkategorien an. Da wir mit unserem Modell nur **Früchte** klassizieren möchten, reduzieren wir unsere Daten auf die Kategorien: **Apple, Orange, Pear**. Diese Klassen entsprechen den Labels mit der ID: Apple = 0, Orange = 53, Pear = 57."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train = []\n",
    "indices_test = []\n",
    "\n",
    "# Wir untersuchen, ob es sich bei einem Eintrag der Trainings-Labels um eines der Früchte handelt.\n",
    "# Falls ja, fügen wir dessen Index einem zuvor initialisiertem Array hinzu.\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i] == 0 or y_train[i] == 53 or y_train[i] == 57:\n",
    "        indices_train.append(i)\n",
    "\n",
    "# Selbiges führen wir für alle Test-Labels durch.\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] == 0 or y_test[i] == 53 or y_test[i] == 57:\n",
    "        indices_test.append(i)\n",
    "\n",
    "# Wir reduzieren unsere Trainings- und Test-Labels auf alle die, der Früchte.\n",
    "y_train = np.array(y_train[indices_train])\n",
    "y_test = np.array(y_test[indices_test])\n",
    "\n",
    "# Wir reduzieren unsere Trainings- und Testdaten auf alle die, der Früchte.\n",
    "x_train = x_train[np.ravel(indices_train)]\n",
    "x_test = x_test[np.ravel(indices_test)]\n",
    "\n",
    "# Für die Konvertierung unserer Label-Vektoren in Binäre-Klassenmatrizen, ändern wir alle ursprünglichen\n",
    "# Trainings- und Test-Labels in die Werte 0-2.\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i] == 0:\n",
    "        np.put(y_train, i, 0)\n",
    "    elif y_train[i] == 53:\n",
    "        np.put(y_train, i, 1)\n",
    "    elif y_train[i] == 57:\n",
    "        np.put(y_train, i, 2)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] == 0:\n",
    "        np.put(y_test, i, 0)\n",
    "    elif y_test[i] == 53:\n",
    "        np.put(y_test, i, 1)\n",
    "    elif y_test[i] == 57:\n",
    "        np.put(y_test, i, 2)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Wir dividieren für eine Normalisierung jeden unsere Bilderwerte [0;255] in Werte zwischen [0;1].\n",
    "# Dieser Schritt dient in unsere Modell einer Verbesserung der \"Accuracy\".\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Die Konvertierung unser Label-Vektoren in Binäre-Klassenmatrizen wird für unseren Datensatz benötigt.\n",
    "y_train = to_categorical(y_train, 3)\n",
    "y_test = to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im folgenden Schritt definieren wir unser Modell. Wir nutzen für die Klassifizierung unserer Bilder ein **Convolutional Neural Network (CNN)**. Das Modell besteht aus vier *Convolutional Layern* und drei *Pooling Layern*. Unsere Filtergröße beträgt *3 x 3*. Wir verwenden für jede Schicht die *ReĹu*-Aktivierungsfunktion. Nur unser Ausgabeschicht verwendet eine *Softmax*-Aktivierungsfunktionen. Als Error-Funktion kommt für Multiklassifizierung bestimmte *Categorial_Crossentropy*  zum Einsatz. Als Optimierer benutzen wir den stochastischen Optimierer *Adam*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir definieren unser Model über einen Stapel von Schichten. Hierzu initialisieren wir unser sequentialles Modell.\n",
    "model = Sequential()\n",
    "model.add(Conv2D(96, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Trainieren des Modells übergeben wir der **fit()**-Methode unsere Trainingsdaten und -Labels. Das Modell wird über 5 Epochen trainiert. Wir verwenden unsere Testdaten und -Labels zur Validierung unseres Modells nach jeder Epoche über das Argument *validation_data*. \"Loss\" und \"Accuracy\" werden standardmäßig nach jeder Epoche und nach dem Trainieren ausgegeben (verbose default: 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um unser Modell für weitere Aufgaben verwenden zu können nutzen wir die **save**-Methode zur Speicherung unseres Modells als Datei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
